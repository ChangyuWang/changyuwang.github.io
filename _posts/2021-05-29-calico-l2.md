---
title:  "Calico: 基于BGP构建二层网络"
tags:   network
---

Calico基于BGP实现的容器网络方案较为经典，这里分两个篇幅分别介绍二层和三层网络方案的实现机制，本文侧重介绍如何基于BGP实现二层网络方案。

<!--more-->

# Preface
本文不对二层网络的多种实现方式做展开说明，侧重介绍在大规模集群的生产实践中，面对二层网络中存在的一些痛点问题，Calico是如何解决的，并且做到生产级可用。鉴于Calico主要是基于BGP协议实现的网络方案，在开始阅读本文之前，希望读者对BGP协议[1]有所了解,熟悉基础的Route Reflector[2]路由学习原理。


# Concerns over Ethernet
大规模Kubernetes集群的容器管理中，容器之间要实现二层网络通信，通信双方都能学习到对端的Mac地址。该场景下存在着诸多限制因素，归纳起来为以下四点：

* **较大规模的Pod数量**

  Pod之间要实现二层互通，源Pod要学习到目的Pod的Mac地址，并且途径的每个交换机都需要学习到源Pod和目的Pod的Mac地址记录到FDB中。当整个集群管理的Pod规模达到上万数量的时候，组网中的每台交换机就需要学习到集群中所有Pod的Mac并维护在一个庞大FDB表，对交换机来说负载是巨大的。

* **高频率的Pod变更**

  容器的生命周期很短暂，Pod会被经常创建和销毁，对应事件发生后交换机需要进行路径的重新学习，学习的过程增加了交换机的负载。

* **广播风暴**

  Pod之间进行通信的时候需要通过ARP广播学习对端的Mac，当集群规模很大的时候会产生大量的ARP广播风暴，从而导致整个集群不可用。

* **生成树协议**

  二层网络为了防止环路引入STP，但是STP只能支撑小规模的组网，当以太网中链路和互联节点数量增加时，STP会变的脆弱，一旦STP失效，对整个集群的影响是灾难性的。


# Solutions over Ethernet
针对Pod之间二层通信时存在的以上四个痛点，我们来看下Calico中是如何处理的。我们知道二层网络终结于路由，每个二层网络只能看到它自己的网关，Calico的网络实现中，将Pod的二层网络终结在Node上，即Pod发出的ARP广播不会扩散到Node之外，该场景下不会对既有的组网产生冲击，交换机只需要学习其管理Node Mac即可，

* **较大规模的Pod数量**

  Calico网络模型二层实现的互联场景下，接入层交换机只能看到Node，不能看到Node上的Pod。每个接入层交换机下的Node数量是可控的，Node上可能管理着几百个Pod，Pod产生的ARP广播终结在Node上。

* **高频率的Pod变更**

  Calico网络中，因为接入层交换机看到的只有Node，Node的变更频率通常较低，Node上的Pod变更频率虽然高，但是交换机感知不到。

* **广播风暴**

  Calico网络中，Pod之间进行网络通信时，Pod发出的报文下一跳指向Node，网关下一跳直接将Pod发出的ARP报文终结在了Node上。进入Pod的报文到达Node上后被通过路由送到Pod内。所以正常情况下，ARP的变更速率应该为0，即使数据中心发生了一些故障，ARP的变更速率也应当在一个正常的幅度范围内。

* **生成树协议**

  STP不会受到Pod的地址学习的干扰，只需要关心小规模的Node以太网通信，所以Calico网络中STP可以没有任何压力的处理负载。

# Calico architecture

互联网时代，因为IDC内部处理东西走向的流量剧增，可动态横向扩展，更加扁平化的leaf spine架构体系备受欢迎。Calico网络中使用Leaf Spine架构体系。

Calico使用ECMP多链路分发流量，可以在每个Node节点上利用ECMP负载均衡技术，组网实现模型是通过构建多个Leaf Spine平面，类似于Facebook的立体数据中心[3]平面结构图。这些平面是相互独立的，Fault Domain是分离的，任意一个平面故障都不会影响到整个集群网络，这种设计相比其他的以太网结构体系可用性更高。

<img src="/images/network/calico/l2-spine-planes.png" alt="drawing" width="800"/>

每一个TOR基于vlan被分割成了4个逻辑的Switch平面，对应图中4种颜色，TOR下的每个Node节点分别与4个逻辑Switch平面建立连接，每个逻辑平面独占一个Spine Switch，每个TOR上的逻辑平面只与自己的Spine建立连接。

每一个平面都是一个广播域，构建一个IP网络，假设对应的子网分别为192.168.0.0/24, 192.168.1.0/24, 192.168.2.0/24, 192.168.3.0/24。每个Node节点上分配四个所在逻辑平面的IP地址。

<img src="/images/network/calico/l2-rr-spine-planes.png" alt="drawing" width="800"/>

每个逻辑平面都有一个Route Reflector，充当RR的节点可以是物理交换机，也可以是跑BGP服务的Node节点，RR与所在逻辑平面下的所有Node节点建立BGP连接，用于进行路由反射，每个Node节点上跑BGP服务，宣告本节点的路由信息：Pod CIDR，通过RR将Pod CIDR反射给同一逻辑平面内的其他节点。最终Node节点上会学习到其他节点上的4个等价路由，下图以NodeA和NodeC为例展示具体的路由表学习。

<img src="/images/network/calico/l2-routing.png" alt="drawing" width="800"/>


# Reference
1. https://datatracker.ietf.org/doc/html/rfc4271
2. https://datatracker.ietf.org/doc/html/rfc4456
3. https://engineering.fb.com/2014/11/14/production-engineering/introducing-data-center-fabric-the-next-generation-facebook-data-center-network/